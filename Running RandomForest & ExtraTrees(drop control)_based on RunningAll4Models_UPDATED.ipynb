{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df2cc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we may need\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seaborn import set_style\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.multiclass import OneVsRestClassifier  # Correct location for OneVsRestClassifier\n",
    "from scipy.stats import sem\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a4ac179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest for feature importances\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65fa4b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Q15389</th>\n",
       "      <th>P29965</th>\n",
       "      <th>P49763</th>\n",
       "      <th>Q02763</th>\n",
       "      <th>P01127</th>\n",
       "      <th>P09341</th>\n",
       "      <th>...</th>\n",
       "      <th>P09382</th>\n",
       "      <th>Q16790</th>\n",
       "      <th>P26842</th>\n",
       "      <th>P14210</th>\n",
       "      <th>P43489</th>\n",
       "      <th>O75144</th>\n",
       "      <th>O43927</th>\n",
       "      <th>P32970</th>\n",
       "      <th>Q8WXI7</th>\n",
       "      <th>P10144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PM910</td>\n",
       "      <td>Ctrl</td>\n",
       "      <td>10.12895</td>\n",
       "      <td>5.62622</td>\n",
       "      <td>7.72902</td>\n",
       "      <td>8.47530</td>\n",
       "      <td>10.08926</td>\n",
       "      <td>10.58751</td>\n",
       "      <td>...</td>\n",
       "      <td>8.54519</td>\n",
       "      <td>4.20874</td>\n",
       "      <td>10.61404</td>\n",
       "      <td>8.37166</td>\n",
       "      <td>4.99296</td>\n",
       "      <td>7.78219</td>\n",
       "      <td>7.03584</td>\n",
       "      <td>4.81481</td>\n",
       "      <td>3.58965</td>\n",
       "      <td>4.13563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PM396</td>\n",
       "      <td>Ctrl</td>\n",
       "      <td>8.67289</td>\n",
       "      <td>5.18821</td>\n",
       "      <td>8.25523</td>\n",
       "      <td>9.06271</td>\n",
       "      <td>8.89866</td>\n",
       "      <td>9.22360</td>\n",
       "      <td>...</td>\n",
       "      <td>8.25401</td>\n",
       "      <td>3.46839</td>\n",
       "      <td>10.77271</td>\n",
       "      <td>8.36820</td>\n",
       "      <td>4.92422</td>\n",
       "      <td>7.47997</td>\n",
       "      <td>8.05700</td>\n",
       "      <td>3.98900</td>\n",
       "      <td>4.78155</td>\n",
       "      <td>3.14840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PM190</td>\n",
       "      <td>Ctrl</td>\n",
       "      <td>9.99567</td>\n",
       "      <td>6.38876</td>\n",
       "      <td>8.44263</td>\n",
       "      <td>8.42102</td>\n",
       "      <td>10.08508</td>\n",
       "      <td>10.43894</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75887</td>\n",
       "      <td>4.65936</td>\n",
       "      <td>11.03062</td>\n",
       "      <td>9.18464</td>\n",
       "      <td>5.60743</td>\n",
       "      <td>7.92803</td>\n",
       "      <td>8.77261</td>\n",
       "      <td>4.80189</td>\n",
       "      <td>5.16350</td>\n",
       "      <td>4.29062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PM270</td>\n",
       "      <td>Ctrl</td>\n",
       "      <td>8.26407</td>\n",
       "      <td>5.06228</td>\n",
       "      <td>8.13429</td>\n",
       "      <td>8.66165</td>\n",
       "      <td>8.75925</td>\n",
       "      <td>9.24310</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75741</td>\n",
       "      <td>4.44633</td>\n",
       "      <td>10.47952</td>\n",
       "      <td>8.65548</td>\n",
       "      <td>5.54289</td>\n",
       "      <td>9.29458</td>\n",
       "      <td>8.64028</td>\n",
       "      <td>4.04045</td>\n",
       "      <td>5.59217</td>\n",
       "      <td>3.75295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PM656</td>\n",
       "      <td>Ctrl</td>\n",
       "      <td>9.08833</td>\n",
       "      <td>5.95005</td>\n",
       "      <td>8.37830</td>\n",
       "      <td>8.29127</td>\n",
       "      <td>9.43936</td>\n",
       "      <td>9.83732</td>\n",
       "      <td>...</td>\n",
       "      <td>8.48018</td>\n",
       "      <td>3.81634</td>\n",
       "      <td>10.59295</td>\n",
       "      <td>8.63758</td>\n",
       "      <td>5.16271</td>\n",
       "      <td>7.41098</td>\n",
       "      <td>8.29143</td>\n",
       "      <td>4.59594</td>\n",
       "      <td>4.91665</td>\n",
       "      <td>4.10381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C29ZZ80Y4.01</td>\n",
       "      <td>HODG</td>\n",
       "      <td>9.87819</td>\n",
       "      <td>7.15139</td>\n",
       "      <td>7.71189</td>\n",
       "      <td>7.72042</td>\n",
       "      <td>10.23705</td>\n",
       "      <td>7.66455</td>\n",
       "      <td>...</td>\n",
       "      <td>7.19963</td>\n",
       "      <td>4.26576</td>\n",
       "      <td>7.80544</td>\n",
       "      <td>9.24521</td>\n",
       "      <td>5.59883</td>\n",
       "      <td>5.16395</td>\n",
       "      <td>9.03873</td>\n",
       "      <td>4.24414</td>\n",
       "      <td>1.53814</td>\n",
       "      <td>5.30002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C29ZS2ML8.01</td>\n",
       "      <td>HODG</td>\n",
       "      <td>9.42403</td>\n",
       "      <td>6.16559</td>\n",
       "      <td>7.48199</td>\n",
       "      <td>7.30005</td>\n",
       "      <td>10.14143</td>\n",
       "      <td>7.84437</td>\n",
       "      <td>...</td>\n",
       "      <td>6.90334</td>\n",
       "      <td>4.14795</td>\n",
       "      <td>7.74788</td>\n",
       "      <td>8.80026</td>\n",
       "      <td>5.18470</td>\n",
       "      <td>7.53391</td>\n",
       "      <td>7.97077</td>\n",
       "      <td>3.84446</td>\n",
       "      <td>3.41778</td>\n",
       "      <td>3.84928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C29ZFFZ0Q.01</td>\n",
       "      <td>HODG</td>\n",
       "      <td>10.26858</td>\n",
       "      <td>8.11759</td>\n",
       "      <td>7.78457</td>\n",
       "      <td>7.46200</td>\n",
       "      <td>10.25920</td>\n",
       "      <td>8.15014</td>\n",
       "      <td>...</td>\n",
       "      <td>6.69773</td>\n",
       "      <td>3.60838</td>\n",
       "      <td>7.67268</td>\n",
       "      <td>7.83666</td>\n",
       "      <td>5.35574</td>\n",
       "      <td>5.27098</td>\n",
       "      <td>7.55698</td>\n",
       "      <td>3.11025</td>\n",
       "      <td>1.56641</td>\n",
       "      <td>4.23022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C29ZQOG4N.01</td>\n",
       "      <td>HODG</td>\n",
       "      <td>10.15491</td>\n",
       "      <td>7.09910</td>\n",
       "      <td>7.78078</td>\n",
       "      <td>7.45732</td>\n",
       "      <td>10.27589</td>\n",
       "      <td>8.17975</td>\n",
       "      <td>...</td>\n",
       "      <td>7.01314</td>\n",
       "      <td>5.67411</td>\n",
       "      <td>8.44027</td>\n",
       "      <td>8.79263</td>\n",
       "      <td>5.66616</td>\n",
       "      <td>7.99492</td>\n",
       "      <td>8.71554</td>\n",
       "      <td>5.02993</td>\n",
       "      <td>3.94930</td>\n",
       "      <td>4.90380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C29ZPXKPU.01</td>\n",
       "      <td>HODG</td>\n",
       "      <td>9.91994</td>\n",
       "      <td>8.26728</td>\n",
       "      <td>8.24490</td>\n",
       "      <td>7.38531</td>\n",
       "      <td>10.22731</td>\n",
       "      <td>8.95367</td>\n",
       "      <td>...</td>\n",
       "      <td>7.15677</td>\n",
       "      <td>3.31914</td>\n",
       "      <td>7.24481</td>\n",
       "      <td>9.03534</td>\n",
       "      <td>5.98560</td>\n",
       "      <td>6.32338</td>\n",
       "      <td>8.23345</td>\n",
       "      <td>3.41871</td>\n",
       "      <td>2.53294</td>\n",
       "      <td>4.79012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1905 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0     Sample_ID Cancer    Q15389   P29965  \\\n",
       "0                0         0.0         PM910   Ctrl  10.12895  5.62622   \n",
       "1                1         1.0         PM396   Ctrl   8.67289  5.18821   \n",
       "2                2         2.0         PM190   Ctrl   9.99567  6.38876   \n",
       "3                3         3.0         PM270   Ctrl   8.26407  5.06228   \n",
       "4                4         4.0         PM656   Ctrl   9.08833  5.95005   \n",
       "...            ...         ...           ...    ...       ...      ...   \n",
       "1900           162         NaN  C29ZZ80Y4.01   HODG   9.87819  7.15139   \n",
       "1901           163         NaN  C29ZS2ML8.01   HODG   9.42403  6.16559   \n",
       "1902           164         NaN  C29ZFFZ0Q.01   HODG  10.26858  8.11759   \n",
       "1903           165         NaN  C29ZQOG4N.01   HODG  10.15491  7.09910   \n",
       "1904           166         NaN  C29ZPXKPU.01   HODG   9.91994  8.26728   \n",
       "\n",
       "       P49763   Q02763    P01127    P09341  ...   P09382   Q16790    P26842  \\\n",
       "0     7.72902  8.47530  10.08926  10.58751  ...  8.54519  4.20874  10.61404   \n",
       "1     8.25523  9.06271   8.89866   9.22360  ...  8.25401  3.46839  10.77271   \n",
       "2     8.44263  8.42102  10.08508  10.43894  ...  8.75887  4.65936  11.03062   \n",
       "3     8.13429  8.66165   8.75925   9.24310  ...  8.75741  4.44633  10.47952   \n",
       "4     8.37830  8.29127   9.43936   9.83732  ...  8.48018  3.81634  10.59295   \n",
       "...       ...      ...       ...       ...  ...      ...      ...       ...   \n",
       "1900  7.71189  7.72042  10.23705   7.66455  ...  7.19963  4.26576   7.80544   \n",
       "1901  7.48199  7.30005  10.14143   7.84437  ...  6.90334  4.14795   7.74788   \n",
       "1902  7.78457  7.46200  10.25920   8.15014  ...  6.69773  3.60838   7.67268   \n",
       "1903  7.78078  7.45732  10.27589   8.17975  ...  7.01314  5.67411   8.44027   \n",
       "1904  8.24490  7.38531  10.22731   8.95367  ...  7.15677  3.31914   7.24481   \n",
       "\n",
       "       P14210   P43489   O75144   O43927   P32970   Q8WXI7   P10144  \n",
       "0     8.37166  4.99296  7.78219  7.03584  4.81481  3.58965  4.13563  \n",
       "1     8.36820  4.92422  7.47997  8.05700  3.98900  4.78155  3.14840  \n",
       "2     9.18464  5.60743  7.92803  8.77261  4.80189  5.16350  4.29062  \n",
       "3     8.65548  5.54289  9.29458  8.64028  4.04045  5.59217  3.75295  \n",
       "4     8.63758  5.16271  7.41098  8.29143  4.59594  4.91665  4.10381  \n",
       "...       ...      ...      ...      ...      ...      ...      ...  \n",
       "1900  9.24521  5.59883  5.16395  9.03873  4.24414  1.53814  5.30002  \n",
       "1901  8.80026  5.18470  7.53391  7.97077  3.84446  3.41778  3.84928  \n",
       "1902  7.83666  5.35574  5.27098  7.55698  3.11025  1.56641  4.23022  \n",
       "1903  8.79263  5.66616  7.99492  8.71554  5.02993  3.94930  4.90380  \n",
       "1904  9.03534  5.98560  6.32338  8.23345  3.41871  2.53294  4.79012  \n",
       "\n",
       "[1905 rows x 53 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('Combined_df2.csv')\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f72b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ec161f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the blood cancers into one category\n",
    "df_bloodcombined = df_full.copy(deep = True)\n",
    "df_bloodcombined=df_bloodcombined.replace(to_replace = ['AML', 'CLL', 'LYMPH', 'MYEL'], value = 'BLOOD' )\n",
    "df_bloodcombined = df_bloodcombined[df_bloodcombined['Cancer'] != 'Ctrl'] #Exclude the control group Ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7963626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLOOD',\n",
       " 'BRC',\n",
       " 'CRC',\n",
       " 'CVX',\n",
       " 'ENDC',\n",
       " 'ESO',\n",
       " 'GLIOM',\n",
       " 'HODG',\n",
       " 'LUNGC',\n",
       " 'OVC',\n",
       " 'PRC'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the groups were combined as expected\n",
    "set(df_bloodcombined['Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd2fb326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the protein list \n",
    "proteins=df_bloodcombined.columns[4:]\n",
    "# Check that we have the right number of proteins\n",
    "len(proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa9f72ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Q15389</th>\n",
       "      <th>P29965</th>\n",
       "      <th>P49763</th>\n",
       "      <th>Q02763</th>\n",
       "      <th>P01127</th>\n",
       "      <th>P09341</th>\n",
       "      <th>...</th>\n",
       "      <th>P09382</th>\n",
       "      <th>Q16790</th>\n",
       "      <th>P26842</th>\n",
       "      <th>P14210</th>\n",
       "      <th>P43489</th>\n",
       "      <th>O75144</th>\n",
       "      <th>O43927</th>\n",
       "      <th>P32970</th>\n",
       "      <th>Q8WXI7</th>\n",
       "      <th>P10144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R21043026</td>\n",
       "      <td>ESO</td>\n",
       "      <td>7.89700</td>\n",
       "      <td>5.95495</td>\n",
       "      <td>7.18993</td>\n",
       "      <td>6.73672</td>\n",
       "      <td>9.20713</td>\n",
       "      <td>8.12276</td>\n",
       "      <td>...</td>\n",
       "      <td>6.47513</td>\n",
       "      <td>3.93280</td>\n",
       "      <td>8.13850</td>\n",
       "      <td>8.11352</td>\n",
       "      <td>4.82277</td>\n",
       "      <td>4.98006</td>\n",
       "      <td>7.90284</td>\n",
       "      <td>3.11165</td>\n",
       "      <td>0.30757</td>\n",
       "      <td>5.92401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R21043028</td>\n",
       "      <td>ESO</td>\n",
       "      <td>9.16064</td>\n",
       "      <td>7.98518</td>\n",
       "      <td>7.04327</td>\n",
       "      <td>7.37053</td>\n",
       "      <td>10.38645</td>\n",
       "      <td>10.19887</td>\n",
       "      <td>...</td>\n",
       "      <td>6.75024</td>\n",
       "      <td>2.92104</td>\n",
       "      <td>8.11321</td>\n",
       "      <td>8.87499</td>\n",
       "      <td>4.93184</td>\n",
       "      <td>4.79317</td>\n",
       "      <td>8.93262</td>\n",
       "      <td>3.00711</td>\n",
       "      <td>-0.01885</td>\n",
       "      <td>5.49523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R21043030</td>\n",
       "      <td>ESO</td>\n",
       "      <td>6.78645</td>\n",
       "      <td>4.94000</td>\n",
       "      <td>7.05853</td>\n",
       "      <td>7.59944</td>\n",
       "      <td>9.15866</td>\n",
       "      <td>7.71811</td>\n",
       "      <td>...</td>\n",
       "      <td>6.64692</td>\n",
       "      <td>2.53695</td>\n",
       "      <td>7.94573</td>\n",
       "      <td>7.55372</td>\n",
       "      <td>5.56620</td>\n",
       "      <td>5.18132</td>\n",
       "      <td>7.70059</td>\n",
       "      <td>2.84483</td>\n",
       "      <td>-0.34209</td>\n",
       "      <td>3.98589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>3.0</td>\n",
       "      <td>R21043032</td>\n",
       "      <td>ESO</td>\n",
       "      <td>9.73018</td>\n",
       "      <td>8.19881</td>\n",
       "      <td>6.98395</td>\n",
       "      <td>7.20598</td>\n",
       "      <td>10.52286</td>\n",
       "      <td>9.48919</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85275</td>\n",
       "      <td>3.98974</td>\n",
       "      <td>7.71337</td>\n",
       "      <td>9.46343</td>\n",
       "      <td>5.16836</td>\n",
       "      <td>4.28462</td>\n",
       "      <td>7.92165</td>\n",
       "      <td>3.05020</td>\n",
       "      <td>0.59406</td>\n",
       "      <td>5.50904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>4.0</td>\n",
       "      <td>R21043034</td>\n",
       "      <td>ESO</td>\n",
       "      <td>9.84664</td>\n",
       "      <td>8.96580</td>\n",
       "      <td>7.68547</td>\n",
       "      <td>7.10424</td>\n",
       "      <td>10.35271</td>\n",
       "      <td>10.47091</td>\n",
       "      <td>...</td>\n",
       "      <td>7.19276</td>\n",
       "      <td>4.67845</td>\n",
       "      <td>8.56913</td>\n",
       "      <td>9.11535</td>\n",
       "      <td>6.02129</td>\n",
       "      <td>5.18895</td>\n",
       "      <td>8.46326</td>\n",
       "      <td>4.32549</td>\n",
       "      <td>1.76947</td>\n",
       "      <td>6.26009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  Sample_ID Cancer   Q15389   P29965   P49763  \\\n",
       "170           170         0.0  R21043026    ESO  7.89700  5.95495  7.18993   \n",
       "171           171         1.0  R21043028    ESO  9.16064  7.98518  7.04327   \n",
       "172           172         2.0  R21043030    ESO  6.78645  4.94000  7.05853   \n",
       "173           173         3.0  R21043032    ESO  9.73018  8.19881  6.98395   \n",
       "174           174         4.0  R21043034    ESO  9.84664  8.96580  7.68547   \n",
       "\n",
       "      Q02763    P01127    P09341  ...   P09382   Q16790   P26842   P14210  \\\n",
       "170  6.73672   9.20713   8.12276  ...  6.47513  3.93280  8.13850  8.11352   \n",
       "171  7.37053  10.38645  10.19887  ...  6.75024  2.92104  8.11321  8.87499   \n",
       "172  7.59944   9.15866   7.71811  ...  6.64692  2.53695  7.94573  7.55372   \n",
       "173  7.20598  10.52286   9.48919  ...  6.85275  3.98974  7.71337  9.46343   \n",
       "174  7.10424  10.35271  10.47091  ...  7.19276  4.67845  8.56913  9.11535   \n",
       "\n",
       "      P43489   O75144   O43927   P32970   Q8WXI7   P10144  \n",
       "170  4.82277  4.98006  7.90284  3.11165  0.30757  5.92401  \n",
       "171  4.93184  4.79317  8.93262  3.00711 -0.01885  5.49523  \n",
       "172  5.56620  5.18132  7.70059  2.84483 -0.34209  3.98589  \n",
       "173  5.16836  4.28462  7.92165  3.05020  0.59406  5.50904  \n",
       "174  6.02129  5.18895  8.46326  4.32549  1.76947  6.26009  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bloodcombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3232bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the cancer types as numbers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_bloodcombined['Cancer'] = le.fit_transform(df_bloodcombined['Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1ccfad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Q15389</th>\n",
       "      <th>P29965</th>\n",
       "      <th>P49763</th>\n",
       "      <th>Q02763</th>\n",
       "      <th>P01127</th>\n",
       "      <th>P09341</th>\n",
       "      <th>...</th>\n",
       "      <th>P09382</th>\n",
       "      <th>Q16790</th>\n",
       "      <th>P26842</th>\n",
       "      <th>P14210</th>\n",
       "      <th>P43489</th>\n",
       "      <th>O75144</th>\n",
       "      <th>O43927</th>\n",
       "      <th>P32970</th>\n",
       "      <th>Q8WXI7</th>\n",
       "      <th>P10144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R21043026</td>\n",
       "      <td>5</td>\n",
       "      <td>7.89700</td>\n",
       "      <td>5.95495</td>\n",
       "      <td>7.18993</td>\n",
       "      <td>6.73672</td>\n",
       "      <td>9.20713</td>\n",
       "      <td>8.12276</td>\n",
       "      <td>...</td>\n",
       "      <td>6.47513</td>\n",
       "      <td>3.93280</td>\n",
       "      <td>8.13850</td>\n",
       "      <td>8.11352</td>\n",
       "      <td>4.82277</td>\n",
       "      <td>4.98006</td>\n",
       "      <td>7.90284</td>\n",
       "      <td>3.11165</td>\n",
       "      <td>0.30757</td>\n",
       "      <td>5.92401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R21043028</td>\n",
       "      <td>5</td>\n",
       "      <td>9.16064</td>\n",
       "      <td>7.98518</td>\n",
       "      <td>7.04327</td>\n",
       "      <td>7.37053</td>\n",
       "      <td>10.38645</td>\n",
       "      <td>10.19887</td>\n",
       "      <td>...</td>\n",
       "      <td>6.75024</td>\n",
       "      <td>2.92104</td>\n",
       "      <td>8.11321</td>\n",
       "      <td>8.87499</td>\n",
       "      <td>4.93184</td>\n",
       "      <td>4.79317</td>\n",
       "      <td>8.93262</td>\n",
       "      <td>3.00711</td>\n",
       "      <td>-0.01885</td>\n",
       "      <td>5.49523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R21043030</td>\n",
       "      <td>5</td>\n",
       "      <td>6.78645</td>\n",
       "      <td>4.94000</td>\n",
       "      <td>7.05853</td>\n",
       "      <td>7.59944</td>\n",
       "      <td>9.15866</td>\n",
       "      <td>7.71811</td>\n",
       "      <td>...</td>\n",
       "      <td>6.64692</td>\n",
       "      <td>2.53695</td>\n",
       "      <td>7.94573</td>\n",
       "      <td>7.55372</td>\n",
       "      <td>5.56620</td>\n",
       "      <td>5.18132</td>\n",
       "      <td>7.70059</td>\n",
       "      <td>2.84483</td>\n",
       "      <td>-0.34209</td>\n",
       "      <td>3.98589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>3.0</td>\n",
       "      <td>R21043032</td>\n",
       "      <td>5</td>\n",
       "      <td>9.73018</td>\n",
       "      <td>8.19881</td>\n",
       "      <td>6.98395</td>\n",
       "      <td>7.20598</td>\n",
       "      <td>10.52286</td>\n",
       "      <td>9.48919</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85275</td>\n",
       "      <td>3.98974</td>\n",
       "      <td>7.71337</td>\n",
       "      <td>9.46343</td>\n",
       "      <td>5.16836</td>\n",
       "      <td>4.28462</td>\n",
       "      <td>7.92165</td>\n",
       "      <td>3.05020</td>\n",
       "      <td>0.59406</td>\n",
       "      <td>5.50904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>4.0</td>\n",
       "      <td>R21043034</td>\n",
       "      <td>5</td>\n",
       "      <td>9.84664</td>\n",
       "      <td>8.96580</td>\n",
       "      <td>7.68547</td>\n",
       "      <td>7.10424</td>\n",
       "      <td>10.35271</td>\n",
       "      <td>10.47091</td>\n",
       "      <td>...</td>\n",
       "      <td>7.19276</td>\n",
       "      <td>4.67845</td>\n",
       "      <td>8.56913</td>\n",
       "      <td>9.11535</td>\n",
       "      <td>6.02129</td>\n",
       "      <td>5.18895</td>\n",
       "      <td>8.46326</td>\n",
       "      <td>4.32549</td>\n",
       "      <td>1.76947</td>\n",
       "      <td>6.26009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>5.0</td>\n",
       "      <td>R21043036</td>\n",
       "      <td>5</td>\n",
       "      <td>8.19895</td>\n",
       "      <td>7.56376</td>\n",
       "      <td>7.04752</td>\n",
       "      <td>6.61774</td>\n",
       "      <td>10.11903</td>\n",
       "      <td>9.06302</td>\n",
       "      <td>...</td>\n",
       "      <td>6.81832</td>\n",
       "      <td>3.86512</td>\n",
       "      <td>7.71720</td>\n",
       "      <td>8.14011</td>\n",
       "      <td>4.73799</td>\n",
       "      <td>4.79652</td>\n",
       "      <td>8.38275</td>\n",
       "      <td>2.95944</td>\n",
       "      <td>-0.10825</td>\n",
       "      <td>4.93348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>6.0</td>\n",
       "      <td>R21043038</td>\n",
       "      <td>5</td>\n",
       "      <td>5.58798</td>\n",
       "      <td>2.79903</td>\n",
       "      <td>7.21077</td>\n",
       "      <td>6.94127</td>\n",
       "      <td>7.50286</td>\n",
       "      <td>6.67664</td>\n",
       "      <td>...</td>\n",
       "      <td>6.26755</td>\n",
       "      <td>3.98477</td>\n",
       "      <td>7.56413</td>\n",
       "      <td>8.15752</td>\n",
       "      <td>4.89466</td>\n",
       "      <td>4.74908</td>\n",
       "      <td>7.96553</td>\n",
       "      <td>3.35500</td>\n",
       "      <td>1.10607</td>\n",
       "      <td>3.63704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>7.0</td>\n",
       "      <td>R21043040</td>\n",
       "      <td>5</td>\n",
       "      <td>8.46699</td>\n",
       "      <td>6.91034</td>\n",
       "      <td>6.50469</td>\n",
       "      <td>6.78342</td>\n",
       "      <td>10.18429</td>\n",
       "      <td>8.69485</td>\n",
       "      <td>...</td>\n",
       "      <td>6.70359</td>\n",
       "      <td>3.32699</td>\n",
       "      <td>7.34658</td>\n",
       "      <td>8.38454</td>\n",
       "      <td>4.76504</td>\n",
       "      <td>4.62280</td>\n",
       "      <td>7.18765</td>\n",
       "      <td>2.60255</td>\n",
       "      <td>0.89192</td>\n",
       "      <td>4.53309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>8.0</td>\n",
       "      <td>R21043042</td>\n",
       "      <td>5</td>\n",
       "      <td>9.10919</td>\n",
       "      <td>7.21094</td>\n",
       "      <td>6.74611</td>\n",
       "      <td>7.27319</td>\n",
       "      <td>10.41332</td>\n",
       "      <td>9.50338</td>\n",
       "      <td>...</td>\n",
       "      <td>6.56869</td>\n",
       "      <td>3.43928</td>\n",
       "      <td>7.49282</td>\n",
       "      <td>8.34984</td>\n",
       "      <td>5.33802</td>\n",
       "      <td>4.69552</td>\n",
       "      <td>7.28293</td>\n",
       "      <td>2.62003</td>\n",
       "      <td>1.27568</td>\n",
       "      <td>4.00356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>9.0</td>\n",
       "      <td>R21043044</td>\n",
       "      <td>5</td>\n",
       "      <td>8.53798</td>\n",
       "      <td>7.43981</td>\n",
       "      <td>6.80470</td>\n",
       "      <td>7.42369</td>\n",
       "      <td>10.13412</td>\n",
       "      <td>7.75230</td>\n",
       "      <td>...</td>\n",
       "      <td>6.60876</td>\n",
       "      <td>4.18258</td>\n",
       "      <td>7.67294</td>\n",
       "      <td>8.60485</td>\n",
       "      <td>4.70439</td>\n",
       "      <td>4.98824</td>\n",
       "      <td>8.45798</td>\n",
       "      <td>3.08447</td>\n",
       "      <td>0.27582</td>\n",
       "      <td>5.11205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>R21043046</td>\n",
       "      <td>5</td>\n",
       "      <td>8.88899</td>\n",
       "      <td>7.06728</td>\n",
       "      <td>6.52840</td>\n",
       "      <td>7.35645</td>\n",
       "      <td>10.38652</td>\n",
       "      <td>9.22406</td>\n",
       "      <td>...</td>\n",
       "      <td>6.63833</td>\n",
       "      <td>3.97749</td>\n",
       "      <td>7.72632</td>\n",
       "      <td>8.23770</td>\n",
       "      <td>5.60771</td>\n",
       "      <td>5.31671</td>\n",
       "      <td>8.01767</td>\n",
       "      <td>3.50557</td>\n",
       "      <td>0.76520</td>\n",
       "      <td>5.00412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>11.0</td>\n",
       "      <td>R21043048</td>\n",
       "      <td>5</td>\n",
       "      <td>9.36959</td>\n",
       "      <td>6.77972</td>\n",
       "      <td>7.56843</td>\n",
       "      <td>7.65259</td>\n",
       "      <td>10.68089</td>\n",
       "      <td>9.74293</td>\n",
       "      <td>...</td>\n",
       "      <td>6.94460</td>\n",
       "      <td>4.93810</td>\n",
       "      <td>7.93896</td>\n",
       "      <td>8.93465</td>\n",
       "      <td>5.59969</td>\n",
       "      <td>5.99280</td>\n",
       "      <td>8.22760</td>\n",
       "      <td>4.31288</td>\n",
       "      <td>3.68602</td>\n",
       "      <td>4.15889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>12.0</td>\n",
       "      <td>R21043050</td>\n",
       "      <td>5</td>\n",
       "      <td>9.94922</td>\n",
       "      <td>7.30453</td>\n",
       "      <td>6.64362</td>\n",
       "      <td>7.47829</td>\n",
       "      <td>10.30418</td>\n",
       "      <td>8.63318</td>\n",
       "      <td>...</td>\n",
       "      <td>6.02943</td>\n",
       "      <td>3.66471</td>\n",
       "      <td>6.70479</td>\n",
       "      <td>8.50976</td>\n",
       "      <td>4.11561</td>\n",
       "      <td>4.89866</td>\n",
       "      <td>7.41341</td>\n",
       "      <td>2.25969</td>\n",
       "      <td>0.14132</td>\n",
       "      <td>4.53450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>13.0</td>\n",
       "      <td>R21043052</td>\n",
       "      <td>5</td>\n",
       "      <td>7.43432</td>\n",
       "      <td>4.64334</td>\n",
       "      <td>7.28052</td>\n",
       "      <td>7.05280</td>\n",
       "      <td>9.30569</td>\n",
       "      <td>7.62426</td>\n",
       "      <td>...</td>\n",
       "      <td>6.59499</td>\n",
       "      <td>4.67583</td>\n",
       "      <td>7.60501</td>\n",
       "      <td>8.67558</td>\n",
       "      <td>5.44897</td>\n",
       "      <td>4.85879</td>\n",
       "      <td>7.82751</td>\n",
       "      <td>2.75361</td>\n",
       "      <td>2.56747</td>\n",
       "      <td>6.69391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>14.0</td>\n",
       "      <td>R21043054</td>\n",
       "      <td>5</td>\n",
       "      <td>7.87437</td>\n",
       "      <td>5.25781</td>\n",
       "      <td>6.49361</td>\n",
       "      <td>6.81187</td>\n",
       "      <td>9.35013</td>\n",
       "      <td>7.96114</td>\n",
       "      <td>...</td>\n",
       "      <td>5.88565</td>\n",
       "      <td>3.81947</td>\n",
       "      <td>6.71465</td>\n",
       "      <td>7.66138</td>\n",
       "      <td>4.43415</td>\n",
       "      <td>4.62458</td>\n",
       "      <td>6.95143</td>\n",
       "      <td>2.50720</td>\n",
       "      <td>1.01081</td>\n",
       "      <td>3.78612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  Sample_ID  Cancer   Q15389   P29965   P49763  \\\n",
       "170           170         0.0  R21043026       5  7.89700  5.95495  7.18993   \n",
       "171           171         1.0  R21043028       5  9.16064  7.98518  7.04327   \n",
       "172           172         2.0  R21043030       5  6.78645  4.94000  7.05853   \n",
       "173           173         3.0  R21043032       5  9.73018  8.19881  6.98395   \n",
       "174           174         4.0  R21043034       5  9.84664  8.96580  7.68547   \n",
       "175           175         5.0  R21043036       5  8.19895  7.56376  7.04752   \n",
       "176           176         6.0  R21043038       5  5.58798  2.79903  7.21077   \n",
       "177           177         7.0  R21043040       5  8.46699  6.91034  6.50469   \n",
       "178           178         8.0  R21043042       5  9.10919  7.21094  6.74611   \n",
       "179           179         9.0  R21043044       5  8.53798  7.43981  6.80470   \n",
       "180           180        10.0  R21043046       5  8.88899  7.06728  6.52840   \n",
       "181           181        11.0  R21043048       5  9.36959  6.77972  7.56843   \n",
       "182           182        12.0  R21043050       5  9.94922  7.30453  6.64362   \n",
       "183           183        13.0  R21043052       5  7.43432  4.64334  7.28052   \n",
       "184           184        14.0  R21043054       5  7.87437  5.25781  6.49361   \n",
       "\n",
       "      Q02763    P01127    P09341  ...   P09382   Q16790   P26842   P14210  \\\n",
       "170  6.73672   9.20713   8.12276  ...  6.47513  3.93280  8.13850  8.11352   \n",
       "171  7.37053  10.38645  10.19887  ...  6.75024  2.92104  8.11321  8.87499   \n",
       "172  7.59944   9.15866   7.71811  ...  6.64692  2.53695  7.94573  7.55372   \n",
       "173  7.20598  10.52286   9.48919  ...  6.85275  3.98974  7.71337  9.46343   \n",
       "174  7.10424  10.35271  10.47091  ...  7.19276  4.67845  8.56913  9.11535   \n",
       "175  6.61774  10.11903   9.06302  ...  6.81832  3.86512  7.71720  8.14011   \n",
       "176  6.94127   7.50286   6.67664  ...  6.26755  3.98477  7.56413  8.15752   \n",
       "177  6.78342  10.18429   8.69485  ...  6.70359  3.32699  7.34658  8.38454   \n",
       "178  7.27319  10.41332   9.50338  ...  6.56869  3.43928  7.49282  8.34984   \n",
       "179  7.42369  10.13412   7.75230  ...  6.60876  4.18258  7.67294  8.60485   \n",
       "180  7.35645  10.38652   9.22406  ...  6.63833  3.97749  7.72632  8.23770   \n",
       "181  7.65259  10.68089   9.74293  ...  6.94460  4.93810  7.93896  8.93465   \n",
       "182  7.47829  10.30418   8.63318  ...  6.02943  3.66471  6.70479  8.50976   \n",
       "183  7.05280   9.30569   7.62426  ...  6.59499  4.67583  7.60501  8.67558   \n",
       "184  6.81187   9.35013   7.96114  ...  5.88565  3.81947  6.71465  7.66138   \n",
       "\n",
       "      P43489   O75144   O43927   P32970   Q8WXI7   P10144  \n",
       "170  4.82277  4.98006  7.90284  3.11165  0.30757  5.92401  \n",
       "171  4.93184  4.79317  8.93262  3.00711 -0.01885  5.49523  \n",
       "172  5.56620  5.18132  7.70059  2.84483 -0.34209  3.98589  \n",
       "173  5.16836  4.28462  7.92165  3.05020  0.59406  5.50904  \n",
       "174  6.02129  5.18895  8.46326  4.32549  1.76947  6.26009  \n",
       "175  4.73799  4.79652  8.38275  2.95944 -0.10825  4.93348  \n",
       "176  4.89466  4.74908  7.96553  3.35500  1.10607  3.63704  \n",
       "177  4.76504  4.62280  7.18765  2.60255  0.89192  4.53309  \n",
       "178  5.33802  4.69552  7.28293  2.62003  1.27568  4.00356  \n",
       "179  4.70439  4.98824  8.45798  3.08447  0.27582  5.11205  \n",
       "180  5.60771  5.31671  8.01767  3.50557  0.76520  5.00412  \n",
       "181  5.59969  5.99280  8.22760  4.31288  3.68602  4.15889  \n",
       "182  4.11561  4.89866  7.41341  2.25969  0.14132  4.53450  \n",
       "183  5.44897  4.85879  7.82751  2.75361  2.56747  6.69391  \n",
       "184  4.43415  4.62458  6.95143  2.50720  1.01081  3.78612  \n",
       "\n",
       "[15 rows x 53 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bloodcombined.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd812c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = df_bloodcombined[proteins]\n",
    "y = df_bloodcombined['Cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "413ef309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q15389</th>\n",
       "      <th>P29965</th>\n",
       "      <th>P49763</th>\n",
       "      <th>Q02763</th>\n",
       "      <th>P01127</th>\n",
       "      <th>P09341</th>\n",
       "      <th>O00182</th>\n",
       "      <th>Q14116</th>\n",
       "      <th>P09601</th>\n",
       "      <th>Q92583</th>\n",
       "      <th>...</th>\n",
       "      <th>P09382</th>\n",
       "      <th>Q16790</th>\n",
       "      <th>P26842</th>\n",
       "      <th>P14210</th>\n",
       "      <th>P43489</th>\n",
       "      <th>O75144</th>\n",
       "      <th>O43927</th>\n",
       "      <th>P32970</th>\n",
       "      <th>Q8WXI7</th>\n",
       "      <th>P10144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7.89700</td>\n",
       "      <td>5.95495</td>\n",
       "      <td>7.18993</td>\n",
       "      <td>6.73672</td>\n",
       "      <td>9.20713</td>\n",
       "      <td>8.12276</td>\n",
       "      <td>7.49495</td>\n",
       "      <td>8.07464</td>\n",
       "      <td>10.29208</td>\n",
       "      <td>9.50124</td>\n",
       "      <td>...</td>\n",
       "      <td>6.47513</td>\n",
       "      <td>3.93280</td>\n",
       "      <td>8.13850</td>\n",
       "      <td>8.11352</td>\n",
       "      <td>4.82277</td>\n",
       "      <td>4.98006</td>\n",
       "      <td>7.90284</td>\n",
       "      <td>3.11165</td>\n",
       "      <td>0.30757</td>\n",
       "      <td>5.92401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>9.16064</td>\n",
       "      <td>7.98518</td>\n",
       "      <td>7.04327</td>\n",
       "      <td>7.37053</td>\n",
       "      <td>10.38645</td>\n",
       "      <td>10.19887</td>\n",
       "      <td>7.62179</td>\n",
       "      <td>8.52729</td>\n",
       "      <td>9.86255</td>\n",
       "      <td>9.45123</td>\n",
       "      <td>...</td>\n",
       "      <td>6.75024</td>\n",
       "      <td>2.92104</td>\n",
       "      <td>8.11321</td>\n",
       "      <td>8.87499</td>\n",
       "      <td>4.93184</td>\n",
       "      <td>4.79317</td>\n",
       "      <td>8.93262</td>\n",
       "      <td>3.00711</td>\n",
       "      <td>-0.01885</td>\n",
       "      <td>5.49523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>6.78645</td>\n",
       "      <td>4.94000</td>\n",
       "      <td>7.05853</td>\n",
       "      <td>7.59944</td>\n",
       "      <td>9.15866</td>\n",
       "      <td>7.71811</td>\n",
       "      <td>7.85300</td>\n",
       "      <td>7.87270</td>\n",
       "      <td>10.65013</td>\n",
       "      <td>7.39922</td>\n",
       "      <td>...</td>\n",
       "      <td>6.64692</td>\n",
       "      <td>2.53695</td>\n",
       "      <td>7.94573</td>\n",
       "      <td>7.55372</td>\n",
       "      <td>5.56620</td>\n",
       "      <td>5.18132</td>\n",
       "      <td>7.70059</td>\n",
       "      <td>2.84483</td>\n",
       "      <td>-0.34209</td>\n",
       "      <td>3.98589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>9.73018</td>\n",
       "      <td>8.19881</td>\n",
       "      <td>6.98395</td>\n",
       "      <td>7.20598</td>\n",
       "      <td>10.52286</td>\n",
       "      <td>9.48919</td>\n",
       "      <td>7.50968</td>\n",
       "      <td>7.94973</td>\n",
       "      <td>9.99707</td>\n",
       "      <td>9.24046</td>\n",
       "      <td>...</td>\n",
       "      <td>6.85275</td>\n",
       "      <td>3.98974</td>\n",
       "      <td>7.71337</td>\n",
       "      <td>9.46343</td>\n",
       "      <td>5.16836</td>\n",
       "      <td>4.28462</td>\n",
       "      <td>7.92165</td>\n",
       "      <td>3.05020</td>\n",
       "      <td>0.59406</td>\n",
       "      <td>5.50904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>9.84664</td>\n",
       "      <td>8.96580</td>\n",
       "      <td>7.68547</td>\n",
       "      <td>7.10424</td>\n",
       "      <td>10.35271</td>\n",
       "      <td>10.47091</td>\n",
       "      <td>8.81068</td>\n",
       "      <td>9.20990</td>\n",
       "      <td>9.61469</td>\n",
       "      <td>11.56641</td>\n",
       "      <td>...</td>\n",
       "      <td>7.19276</td>\n",
       "      <td>4.67845</td>\n",
       "      <td>8.56913</td>\n",
       "      <td>9.11535</td>\n",
       "      <td>6.02129</td>\n",
       "      <td>5.18895</td>\n",
       "      <td>8.46326</td>\n",
       "      <td>4.32549</td>\n",
       "      <td>1.76947</td>\n",
       "      <td>6.26009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q15389   P29965   P49763   Q02763    P01127    P09341   O00182   Q14116  \\\n",
       "170  7.89700  5.95495  7.18993  6.73672   9.20713   8.12276  7.49495  8.07464   \n",
       "171  9.16064  7.98518  7.04327  7.37053  10.38645  10.19887  7.62179  8.52729   \n",
       "172  6.78645  4.94000  7.05853  7.59944   9.15866   7.71811  7.85300  7.87270   \n",
       "173  9.73018  8.19881  6.98395  7.20598  10.52286   9.48919  7.50968  7.94973   \n",
       "174  9.84664  8.96580  7.68547  7.10424  10.35271  10.47091  8.81068  9.20990   \n",
       "\n",
       "       P09601    Q92583  ...   P09382   Q16790   P26842   P14210   P43489  \\\n",
       "170  10.29208   9.50124  ...  6.47513  3.93280  8.13850  8.11352  4.82277   \n",
       "171   9.86255   9.45123  ...  6.75024  2.92104  8.11321  8.87499  4.93184   \n",
       "172  10.65013   7.39922  ...  6.64692  2.53695  7.94573  7.55372  5.56620   \n",
       "173   9.99707   9.24046  ...  6.85275  3.98974  7.71337  9.46343  5.16836   \n",
       "174   9.61469  11.56641  ...  7.19276  4.67845  8.56913  9.11535  6.02129   \n",
       "\n",
       "      O75144   O43927   P32970   Q8WXI7   P10144  \n",
       "170  4.98006  7.90284  3.11165  0.30757  5.92401  \n",
       "171  4.79317  8.93262  3.00711 -0.01885  5.49523  \n",
       "172  5.18132  7.70059  2.84483 -0.34209  3.98589  \n",
       "173  4.28462  7.92165  3.05020  0.59406  5.50904  \n",
       "174  5.18895  8.46326  4.32549  1.76947  6.26009  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b421413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, stratify = y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f409b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20eca02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    #\"Logistic Regression\": OneVsRestClassifier(LogisticRegression(max_iter=100, solver='lbfgs')),\n",
    "    #\"k-Nearest Neighbors (n=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    #\"k-Nearest Neighbors (n=13)\": KNeighborsClassifier(n_neighbors=13),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=100),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=100),\n",
    "    #\"XGBoost\": XGBClassifier(n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cc96f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation and bootstrapping parameters\n",
    "n_splits = 5  # Number of folds\n",
    "n_bootstraps = 1000  # Number of bootstraps for confidence interval calculation\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35a63fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Evaluating Random Forest for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\u001b[0m\n",
      "Fold 1 - Accuracy: 0.5540, F1: 0.5529, ROC AUC: 0.8823\n",
      "Fold 2 - Accuracy: 0.5432, F1: 0.5497, ROC AUC: 0.8722\n",
      "Fold 3 - Accuracy: 0.5540, F1: 0.5504, ROC AUC: 0.8842\n",
      "Fold 4 - Accuracy: 0.5668, F1: 0.5639, ROC AUC: 0.8983\n",
      "Fold 5 - Accuracy: 0.5451, F1: 0.5483, ROC AUC: 0.8746\n",
      "\n",
      "Random Forest - Mean Accuracy: 0.5526 ± 0.0082\n",
      "Random Forest - Mean F1 Score: 0.5530\n",
      "Random Forest - Mean ROC AUC: 0.8823\n",
      "\u001b[1m\n",
      "Evaluating Extra Trees for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\u001b[0m\n",
      "Fold 1 - Accuracy: 0.5468, F1: 0.5435, ROC AUC: 0.8798\n",
      "Fold 2 - Accuracy: 0.5468, F1: 0.5526, ROC AUC: 0.8682\n",
      "Fold 3 - Accuracy: 0.5576, F1: 0.5556, ROC AUC: 0.8872\n",
      "Fold 4 - Accuracy: 0.5632, F1: 0.5586, ROC AUC: 0.8880\n",
      "Fold 5 - Accuracy: 0.5523, F1: 0.5554, ROC AUC: 0.8823\n",
      "\n",
      "Extra Trees - Mean Accuracy: 0.5533 ± 0.0062\n",
      "Extra Trees - Mean F1 Score: 0.5532\n",
      "Extra Trees - Mean ROC AUC: 0.8811\n",
      "\n",
      "Final Test Accuracy: 0.6023\n",
      "Final Test F1 Score: 0.5995\n",
      "Final Test ROC AUC: 0.9033\n"
     ]
    }
   ],
   "source": [
    "#removed bootstrap to run the code faster\n",
    "# Loop over models\n",
    "for model_name, model in models.items():\n",
    "    #print(f\"\\nEvaluating {model_name}... for the common 49 proteins, combined dataset (dropped control group)\")\n",
    "# Print the model evaluation message in bold\n",
    "    print(f\"\\033[1m\\nEvaluating {model_name} for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\\033[0m\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # Initialize KNNImputer for handling missing values\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    \n",
    "    # Containers for accuracy and other metrics\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    fold_confusion_matrices = []\n",
    "\n",
    "    # k-Fold Cross-Validation Loop\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        # Extract train and test sets for the current fold\n",
    "        X_fold_train = X_train.iloc[train_index]\n",
    "        X_fold_test = X_train.iloc[test_index]\n",
    "        y_fold_train = y_train.iloc[train_index]\n",
    "        y_fold_test = y_train.iloc[test_index]\n",
    "\n",
    "        # Apply KNN Imputer to impute missing values for each fold\n",
    "        X_fold_train_imputed = imputer.fit_transform(X_fold_train)\n",
    "        X_fold_test_imputed = imputer.transform(X_fold_test)\n",
    "\n",
    "        # Apply SMOTE to balance the data within each fold\n",
    "        smote = SMOTE(random_state=100)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_fold_train_imputed, y_fold_train)\n",
    "\n",
    "        # Train the model on the bootstrap sample\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Predict and evaluate metrics for this fold\n",
    "        y_pred = model.predict(X_fold_test_imputed)\n",
    "        fold_accuracies.append(accuracy_score(y_fold_test, y_pred))\n",
    "        fold_f1_scores.append(f1_score(y_fold_test, y_pred, average='weighted'))\n",
    "        fold_roc_auc_scores.append(roc_auc_score(y_fold_test, model.predict_proba(X_fold_test_imputed), multi_class='ovr'))\n",
    "        fold_confusion_matrices.append(confusion_matrix(y_fold_test, y_pred))\n",
    "\n",
    "        # Print accuracy and other metrics for this fold\n",
    "        print(f\"Fold {i+1} - Accuracy: {fold_accuracies[-1]:.4f}, F1: {fold_f1_scores[-1]:.4f}, ROC AUC: {fold_roc_auc_scores[-1]:.4f}\")\n",
    "      \n",
    "        ## Plot the confusion matrix as a heatmap\n",
    "        #plt.figure(figsize=(8, 6))\n",
    "        #sns.heatmap(fold_confusion_matrices[-1], annot=True, fmt='d', cmap='Blues', \n",
    "        #            xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "        #plt.xlabel('Predicted Label')\n",
    "        #plt.ylabel('True Label')\n",
    "        #plt.title(f\"Logistic Regression - Fold {i+1} Confusion Matrix\")\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "    # Display averaged accuracy and metrics for the cross-validation\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_f1_score = np.mean(fold_f1_scores)\n",
    "    mean_roc_auc = np.mean(fold_roc_auc_scores)\n",
    "    confidence_interval = 1.96 * sem(fold_accuracies)\n",
    "    \n",
    "    print(f\"\\n{model_name} - Mean Accuracy: {mean_accuracy:.4f} ± {confidence_interval:.4f}\")\n",
    "    print(f\"{model_name} - Mean F1 Score: {mean_f1_score:.4f}\")\n",
    "    print(f\"{model_name} - Mean ROC AUC: {mean_roc_auc:.4f}\")\n",
    "\n",
    "    ## You could plot the confusion matrix for the last fold\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #sns.heatmap(fold_confusion_matrices[-1], annot=True, fmt='d', cmap='Blues', \n",
    "    #            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    #plt.xlabel('Predicted Label')\n",
    "    #plt.ylabel('True Label')\n",
    "    #plt.title(f\"{model_name} - Confusion Matrix (Fold {n_splits})\")\n",
    "    #plt.show()\n",
    "\n",
    "# After cross-validation, we impute on the entire training and test set and train the best model\n",
    "\n",
    "# Assuming the best model was Random Forest (or another model if selected)\n",
    "best_model = RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "# Impute on entire training set\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Impute on the test set (do not fit the imputer again, avoid data leakage)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train on entire training set\n",
    "best_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = best_model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate final performance metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1_score = f1_score(y_test, y_test_pred, average='weighted')\n",
    "test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test_imputed), multi_class='ovr')\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test F1 Score: {test_f1_score:.4f}\")\n",
    "print(f\"Final Test ROC AUC: {test_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83c551b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Evaluating Random Forest for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\u001b[0m\n",
      "Fold 1 - Accuracy: 0.5540, F1: 0.5529, ROC AUC: 0.8823\n",
      "Fold 2 - Accuracy: 0.5432, F1: 0.5497, ROC AUC: 0.8722\n",
      "Fold 3 - Accuracy: 0.5540, F1: 0.5504, ROC AUC: 0.8842\n",
      "Fold 4 - Accuracy: 0.5668, F1: 0.5639, ROC AUC: 0.8983\n",
      "Fold 5 - Accuracy: 0.5451, F1: 0.5483, ROC AUC: 0.8746\n",
      "\n",
      "Random Forest - Mean Accuracy: 0.5526 ± 0.0082\n",
      "Random Forest - Mean F1 Score: 0.5530\n",
      "Random Forest - Mean ROC AUC: 0.8823\n",
      "\u001b[1m\n",
      "Evaluating Extra Trees for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\u001b[0m\n",
      "Fold 1 - Accuracy: 0.5468, F1: 0.5435, ROC AUC: 0.8798\n",
      "Fold 2 - Accuracy: 0.5468, F1: 0.5526, ROC AUC: 0.8682\n",
      "Fold 3 - Accuracy: 0.5576, F1: 0.5556, ROC AUC: 0.8872\n",
      "Fold 4 - Accuracy: 0.5632, F1: 0.5586, ROC AUC: 0.8880\n",
      "Fold 5 - Accuracy: 0.5523, F1: 0.5554, ROC AUC: 0.8823\n",
      "\n",
      "Extra Trees - Mean Accuracy: 0.5533 ± 0.0062\n",
      "Extra Trees - Mean F1 Score: 0.5532\n",
      "Extra Trees - Mean ROC AUC: 0.8811\n",
      "\n",
      "Final Test Accuracy: 0.5793\n",
      "Final Test F1 Score: 0.5797\n",
      "Final Test ROC AUC: 0.8925\n"
     ]
    }
   ],
   "source": [
    "#using pipeline structure for imputation and SMOTE\n",
    "\n",
    "from imblearn.pipeline import Pipeline  # Use imblearn's pipeline\n",
    "\n",
    "# Loop over models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\033[1m\\nEvaluating {model_name} for the common 49 proteins, combined dataset(dropped control, combined BLOOD)\\033[0m\")\n",
    "\n",
    "    # Container for metrics\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    fold_confusion_matrices = []\n",
    "\n",
    "    # k-Fold Cross-Validation Loop\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        # Extract train and test sets for the current fold\n",
    "        X_fold_train = X_train.iloc[train_index]\n",
    "        X_fold_test = X_train.iloc[test_index]\n",
    "        y_fold_train = y_train.iloc[train_index]\n",
    "        y_fold_test = y_train.iloc[test_index]\n",
    "\n",
    "        # Create the pipeline: Imputation -> SMOTE -> Classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', KNNImputer(n_neighbors=5, weights=\"uniform\")),  # kNN Imputation\n",
    "            ('smote', SMOTE(random_state=100)),                        # SMOTE\n",
    "            ('classifier', model)                                       # Model\n",
    "        ])\n",
    "        \n",
    "        # Fit and evaluate the model within the pipeline\n",
    "        pipeline.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predict and evaluate metrics for this fold\n",
    "        y_pred = pipeline.predict(X_fold_test)\n",
    "        fold_accuracies.append(accuracy_score(y_fold_test, y_pred))\n",
    "        fold_f1_scores.append(f1_score(y_fold_test, y_pred, average='weighted'))\n",
    "        fold_roc_auc_scores.append(roc_auc_score(y_fold_test, pipeline.predict_proba(X_fold_test), multi_class='ovr'))\n",
    "        fold_confusion_matrices.append(confusion_matrix(y_fold_test, y_pred))\n",
    "\n",
    "        # Print accuracy and other metrics for this fold\n",
    "        print(f\"Fold {i+1} - Accuracy: {fold_accuracies[-1]:.4f}, F1: {fold_f1_scores[-1]:.4f}, ROC AUC: {fold_roc_auc_scores[-1]:.4f}\")\n",
    "\n",
    "    # Display averaged accuracy and metrics for the cross-validation\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_f1_score = np.mean(fold_f1_scores)\n",
    "    mean_roc_auc = np.mean(fold_roc_auc_scores)\n",
    "    confidence_interval = 1.96 * sem(fold_accuracies)\n",
    "    \n",
    "    print(f\"\\n{model_name} - Mean Accuracy: {mean_accuracy:.4f} ± {confidence_interval:.4f}\")\n",
    "    print(f\"{model_name} - Mean F1 Score: {mean_f1_score:.4f}\")\n",
    "    print(f\"{model_name} - Mean ROC AUC: {mean_roc_auc:.4f}\")\n",
    "\n",
    "    ## Optionally plot the confusion matrix for the last fold\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #sns.heatmap(fold_confusion_matrices[-1], annot=True, fmt='d', cmap='Blues', \n",
    "    #            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    #plt.xlabel('Predicted Label')\n",
    "    #plt.ylabel('True Label')\n",
    "    #plt.title(f\"{model_name} - Confusion Matrix (Fold {n_splits})\")\n",
    "    #plt.show()\n",
    "\n",
    "# After cross-validation, impute on the entire training and test set and train the best model\n",
    "\n",
    "# Assuming the best model was Random Forest (or another model if selected)\n",
    "best_model = RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "\n",
    "# Create the pipeline for final training\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5, weights=\"uniform\")),\n",
    "    ('smote', SMOTE(random_state=100)),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate final performance metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1_score = f1_score(y_test, y_test_pred, average='weighted')\n",
    "test_roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test F1 Score: {test_f1_score:.4f}\")\n",
    "print(f\"Final Test ROC AUC: {test_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3384fc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea12e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24727574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f3611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d44c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f277535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787a8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5722cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.pipeline import Pipeline  # Use imblearn's pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n",
    "\n",
    "# Encode the cancer types as numbers (if necessary)\n",
    "le = LabelEncoder()\n",
    "df_bloodcombined['Cancer'] = le.fit_transform(df_bloodcombined['Cancer'])\n",
    "\n",
    "X = df_bloodcombined[proteins]  # Ensure proteins is defined in your code\n",
    "y = df_bloodcombined['Cancer']\n",
    "\n",
    "# Split data into training and testing sets (but we only use the test set later for final evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=100),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=100),\n",
    "}\n",
    "\n",
    "# Cross-validation parameters\n",
    "n_splits = 5  # Number of folds\n",
    "n_bootstraps = 1000  # Number of bootstraps for confidence interval calculation\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=100)\n",
    "\n",
    "# Loop over models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nEvaluating {model_name} with a pipeline...\")\n",
    "\n",
    "    # Container for metrics\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    fold_confusion_matrices = []  # This needs to be initialized before the fold loop\n",
    "\n",
    "    # k-Fold Cross-Validation Loop\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        # Extract train and test sets for the current fold\n",
    "        X_fold_train = X_train.iloc[train_index]\n",
    "        X_fold_test = X_train.iloc[test_index]\n",
    "        y_fold_train = y_train.iloc[train_index]\n",
    "        y_fold_test = y_train.iloc[test_index]\n",
    "\n",
    "        # Create the pipeline: Imputation -> SMOTE -> Classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', KNNImputer(n_neighbors=5, weights=\"uniform\")),  # kNN Imputation\n",
    "            ('smote', SMOTE(random_state=100)),                        # SMOTE\n",
    "            ('classifier', model)                                       # Model\n",
    "        ])\n",
    "        \n",
    "        # Bootstrapping - List to store bootstrap accuracies\n",
    "        bootstrap_accuracies = []\n",
    "        bootstrap_f1_scores = []\n",
    "        bootstrap_roc_auc_scores = []\n",
    "\n",
    "        # Bootstrapping within the fold\n",
    "        for b in range(n_bootstraps):\n",
    "            # Resample the training data with SMOTE (with replacement)\n",
    "            X_resampled, y_resampled = resample(X_fold_train, y_fold_train, random_state=100)\n",
    "            \n",
    "            # Apply the pipeline to the bootstrap sample\n",
    "            pipeline.fit(X_resampled, y_resampled)\n",
    "\n",
    "            # Predict and evaluate performance on the validation set (test_index)\n",
    "            y_pred = pipeline.predict(X_fold_test)\n",
    "            bootstrap_accuracies.append(accuracy_score(y_fold_test, y_pred))\n",
    "            bootstrap_f1_scores.append(f1_score(y_fold_test, y_pred, average='weighted'))\n",
    "            bootstrap_roc_auc_scores.append(roc_auc_score(y_fold_test, pipeline.predict_proba(X_fold_test), multi_class='ovr'))\n",
    "\n",
    "        # Calculate mean accuracy, F1 score, and ROC AUC for this fold from bootstraps\n",
    "        fold_accuracy = np.mean(bootstrap_accuracies)\n",
    "        fold_f1_score = np.mean(bootstrap_f1_scores)\n",
    "        fold_roc_auc = np.mean(bootstrap_roc_auc_scores)\n",
    "\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "        fold_f1_scores.append(fold_f1_score)\n",
    "        fold_roc_auc_scores.append(fold_roc_auc)\n",
    "\n",
    "        # Calculate and append confusion matrix for this fold\n",
    "        fold_conf_matrix = confusion_matrix(y_fold_test, y_pred)\n",
    "        fold_confusion_matrices.append(fold_conf_matrix)\n",
    "\n",
    "        # Print metrics for this fold\n",
    "        print(f\"Fold {i+1} - Accuracy: {fold_accuracy:.4f}, F1: {fold_f1_score:.4f}, ROC AUC: {fold_roc_auc:.4f}\")\n",
    "\n",
    "    # Display averaged accuracy and metrics for the cross-validation\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    mean_f1_score = np.mean(fold_f1_scores)\n",
    "    mean_roc_auc = np.mean(fold_roc_auc_scores)\n",
    "    confidence_interval = 1.96 * sem(fold_accuracies)\n",
    "    \n",
    "    print(f\"\\n{model_name} - Mean Accuracy: {mean_accuracy:.4f} ± {confidence_interval:.4f}\")\n",
    "    print(f\"{model_name} - Mean F1 Score: {mean_f1_score:.4f}\")\n",
    "    print(f\"{model_name} - Mean ROC AUC: {mean_roc_auc:.4f}\")\n",
    "\n",
    "    # Optionally plot the confusion matrix for the last fold\n",
    "    if fold_confusion_matrices:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(fold_confusion_matrices[-1], annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title(f\"{model_name} - Confusion Matrix (Last Fold)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No confusion matrix to plot for {model_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fc562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7137391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
